F1 QUALIFYING PREDICTION EVALUATION REPORT
==================================================

KEY METRICS SUMMARY:
------------------------------
Metric              model          random_baselineprevious_quali_baseline
-----------------------------------------------------------------
top3_f1             88.2          %46.7          %84.2          %
top5_f1             96.1          %62.4          %98.7          %
position_within_1   100.0         %27.0          %72.5          %
position_within_2   100.0         %50.0          %97.6          %
position_mae        0.61           3.23           0.92           
exact_accuracy      39.0          %11.0          %38.2          %

INTERPRETATION:
------------------------------
- Your model shows excellent performance at predicting top 5 qualifiers
- 100.0% of predictions are within 1 position of actual result
- Your model is 33.7% better than random_baseline, 2.6% worse than previous_quali_baseline

RECOMMENDATIONS:
------------------------------
1. Use F1 score as your primary evaluation metric (especially top3_f1 or top5_f1)
2. Track 'position_within_n' metrics to measure how close predictions are
3. Compare against baselines to demonstrate model value
